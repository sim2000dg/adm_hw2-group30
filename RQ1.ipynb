{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "os.chdir(\"/Volumes/ExtraHDD2/DS_Assignments_Data/ADM_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "# Also converting the column cts in posters to date/time type. This will be useful for later stages\n",
    "posts = pd.read_csv(\"instagram_posts.csv\", delimiter=\"\\t\", parse_dates=[5])\n",
    "profiles = pd.read_csv(\"instagram_profiles.csv\", delimiter=\"\\t\")\n",
    "locations = pd.read_csv(\"instagram_locations.csv\", delimiter=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RQ1 - Basic EDA [H1]\n",
    "# Let's start with a *very* basic summary of the features of the datasets. On a very coarse level of analysis, we can check the number of observations in each dataset. _Posts is definitely the bigger one (challenging especially for our memory), with 42'710'197 observations, followed by _profiles_ (with 4'509'586 observations) and _locations_ (with 1'022'658 observations).\n",
    "# This makes sense considering that for every profile there will be n posts and considering that locations get repeated a lot among posts, with many posts not even having any location. Specifically, to prove the point, locations repeat on average 17 times in the _post_ dataset and there are 12'972'772 posts without locations as can be seen in the code.\n",
    "\n",
    "# Number of observations for dataset\n",
    "print(f\"Number of obs posts:{len(posts)}\")\n",
    "print(f\"Number of obs profiles: {len(profiles)}\")\n",
    "print(f\"Number of obs locations: {len(locations)}\")\n",
    "\n",
    "# Number of non-complete observations for dataset\n",
    "# Is null returns a dataframe of booleans (na or not for each entry). Any returns true for each row (axis=1) which has a true value (a na field) and sums over the booleans, considering False as 0 and True as 1. This is a solution which is more elegant with respect to others.\n",
    "print(f\"Number of non-complete rows in posts: {posts.isnull().any(axis=1).sum()}\")\n",
    "print(f\"Number of non-complete rows in profiles: {profiles.isnull().any(axis=1).sum()}\")\n",
    "print(f\"Number of non-complete rows in locations: {locations.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "# Number of posts without locations\n",
    "print(\"Number of posts without locations: {}\".format(posts[\"location_id\"].isnull().sum()))\n",
    "# Mean number of posts for each location (2 decimal digits)\n",
    "print(\"Mean number of repetitions for each location: {}\".format(round(posts[\"location_id\"].value_counts().mean())))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Features of the post dataset [H2]\n",
    "# First step in any proper EDA is looking at the\n",
    "\n",
    "print(posts.columns.values)\n",
    "\n",
    "# Basic summary statistics for posts\n",
    "print(posts.describe().iloc[1:, 5:])\n",
    "\n",
    "# Plot the # of posts for day of week\n",
    "number_of_weeks = len(posts[\"cts\"].dt.isocalendar().iloc[:, 0:2].drop_duplicates())\n",
    "grouped_dayweek_post = posts.groupby(posts[\"cts\"].dt.dayofweek)\n",
    "week_list = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "count_week = grouped_dayweek_post[\"sid\"].count().set_axis(week_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This normalizes the number of posts giving us the mean number post for each day (across the years)\n",
    "count_week /= number_of_weeks\n",
    "count_week.plot(marker=\"o\")\n",
    "plt.xlabel(\"Day of week\")\n",
    "plt.ylabel(\"# of posts\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Features of the post dataset [H2]\n",
    "print(profiles.columns.values)\n",
    "\n",
    "# Basic summary statistics for profiles\n",
    "profiles.describe().iloc[1:, 2:].drop(\"min\", axis = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Boxplots of numerical features in profiles\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "profiles[[\"following\", \"followers\"]].plot.box(showfliers=False, vert=False, ax=ax, fontsize = \"large\")\n",
    "ax.set_title(\"Boxplots for # of followers and profiles followed per user\", {\"fontsize\":18})\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "profiles[\"n_posts\"].plot.box(showfliers=False, ax = ax, vert = False, fontsize = \"large\")\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "ax.set_title(\"Boxplots for # of posts per user\", {\"fontsize\":18})\n",
    "plt.suptitle(\"Boxplots for the numerical features of the profiles dataset\", fontsize = 40)\n",
    "plt.tight_layout(pad = 2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
