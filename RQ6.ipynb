{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "\n",
    "os.chdir(\"/Volumes/ExtraHDD2/DS_Assignments_Data/ADM_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posts = pd.read_csv(\"instagram_posts.csv\", delimiter=\"\\t\", parse_dates=[5], infer_datetime_format=True)\n",
    "profiles = pd.read_csv(\"instagram_profiles.csv\", delimiter=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Answer to first question of RQ6\n",
    "# Relatively trivial\n",
    "# I spoke with another colleague, and it came up the fact that we could exploit the fact the average change in a signal is just the value at an extreme minus the value at the other extreme divided by the length minus 1\n",
    "\n",
    "differences_array = posts[['profile_id', \"cts\"]].groupby('profile_id').max()-posts[['profile_id', \"cts\"]].groupby('profile_id').min()\n",
    "differences_array[\"count\"] = posts['profile_id'].value_counts() # Here the indexing of differences_array (the profile_id) is used for the alignment\n",
    "differences_array = differences_array[differences_array[\"count\"] != 1]\n",
    "differences_array[\"cts\"] /= differences_array[\"count\"]-1\n",
    "avg_timedelta = differences_array[\"cts\"].mean()\n",
    "# Basic sexagesimal calculus to get the right format, i.e. days/hours/minutes (3600 seconds in an hour, the resulting modulo (remainder minutes) is used as to calculate the minutes)\n",
    "print(\"Average time between two posts: {} days, {} hours, {} minutes\".format(avg_timedelta.days, avg_timedelta.seconds//3600, (avg_timedelta.seconds % 3600)//60))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "differences_array = posts[[\"sid_profile\", \"cts\"]].groupby(\"sid_profile\").max() - posts[[\"sid_profile\", \"cts\"]].groupby(\"sid_profile\").min()\n",
    "differences_array[\"count\"] = posts[\"sid_profile\"].value_counts() # Here the indexing of differences_array (the sid_profile) is used for the alignment\n",
    "\n",
    "differences_array = differences_array[differences_array.index!=-1]\n",
    "differences_array[\"cts\"] /= differences_array[\"count\"]-1\n",
    "\n",
    "# Idea that I had talking with other colleagues, in order to remove (some) noise consider only users which have more than the mean number of posts in the posts dataset\n",
    "differences_array = differences_array[differences_array[\"count\"] >= differences_array[\"count\"].mean()]\n",
    "sid_profile_query = differences_array.sort_values(by=\"cts\").head(3).index.tolist()\n",
    "print(profiles.set_index(\"sid\").loc[sid_profile_query, [\"profile_name\", \"followers\", \"following\"]].to_markdown())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "differences_array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Answer to second question, again relatively trivial\n",
    "\n",
    "## Not to be included in the notebook because there is the function definition upstream\n",
    "def time_interval_obs(interval_list: list[tuple[str | time, str | time]], time_df: pd.DataFrame,\n",
    "                      time_col: str | None = None) -> None:\n",
    "\n",
    "    if not time_col:\n",
    "        dtypes_series = time_df.dtypes.index[time_df.apply(pd.api.types.is_datetime64_any_dtype)]\n",
    "        if dtypes_series.empty:\n",
    "            raise ValueError(\n",
    "                \"The dataframe has no columns for time, you need to pass a dataframe which has at least one\")\n",
    "        elif len(dtypes_series) != 1:\n",
    "            raise TypeError(\"The dataframe has more than one column with datetime 64 dtype.\\n\\\n",
    "                            You need to explicitly tell the function which one to use\")\n",
    "        else:\n",
    "            time_col = dtypes_series[0]\n",
    "\n",
    "    try:\n",
    "        time_df = pd.Series(np.zeros(len(time_df))).set_axis(time_df[time_col])\n",
    "    except KeyError:\n",
    "        raise KeyError(\"The column you specified does not exist in the dataframe\")\n",
    "\n",
    "    n_posts_int_list = [len(time_df.between_time(*interval)) for interval in interval_list]\n",
    "\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    if all([isinstance(x, time) for couple in interval_list for x in couple]):\n",
    "        interval_list = [[str(x) for x in y] for y in interval_list]\n",
    "        plt.bar([\"|\".join(x) for x in interval_list], n_posts_int_list)\n",
    "    elif all([isinstance(x, str) for couple in interval_list for x in couple]):\n",
    "        plt.bar([\"|\".join(x) for x in interval_list], n_posts_int_list)\n",
    "    else:\n",
    "        raise TypeError(\"The inserted interval list needs to have elements of type datetime.time or string\")\n",
    "    plt.xlabel(\"Time Interval\")\n",
    "    plt.ylabel(\"Number of posts\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_hourly_posts = posts[[\"cts\", \"numbr_likes\", \"number_comments\"]].groupby(posts.cts.dt.hour)\n",
    "likes_comments_hourly = grouped_hourly_posts.mean(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Top 3 time intervals for likes\n",
    "hours_best_like = likes_comments_hourly[\"numbr_likes\"].sort_values(ascending=False).index[:3]\n",
    "intervals_best_like = [(datetime.strptime(str(x), \"%H.0\").time(), (datetime.strptime(str(x), \"%H.0\") + timedelta(hours = 1)).time()) for x in hours_best_like]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Top 3 time intervals for comments\n",
    "hours_best_comment = likes_comments_hourly[\"number_comments\"].sort_values(ascending=False).index[:3]\n",
    "intervals_best_comment = [(datetime.strptime(str(x), \"%H.0\").time(), (datetime.strptime(str(x), \"%H.0\") + timedelta(hours = 1)).time()) for x in hours_best_comment]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot number of posts for time intervals with the highest average number of likes\n",
    "intervals_best_like.sort(key=lambda x:x[0])\n",
    "time_interval_obs(intervals_best_like, posts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot number of posts for time interval with the highest average number of comments\n",
    "intervals_best_comment.sort(key=lambda x:x[0])\n",
    "time_interval_obs(intervals_best_comment, posts)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
